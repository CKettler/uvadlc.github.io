{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1 Intro to Torch [+50 points in total, +20 optional points]\n",
    "________________________________________\n",
    "\n",
    "Before starting working on the assignment, please make sure you have read the [introductory lecture](http://uvadlc.github.io/lecture_notes.html#intro-to-torch \"Intro to Torch\") notes for Lua and Torch. Once you have read it, you are in good enough position to start completing the assignment.\n",
    "\n",
    "Each assignment will contain several files that need to be completed/implemented. This Jypyter notebook serves only as a \"glue\", to connect everything together and let you run the code more easily. If you want to run a particular file, you just need to type in a standard code cell the following\n",
    "\n",
    "```lua\n",
    "dofile 'mynewfile.lua'\n",
    "```\n",
    "\n",
    "and it will run your code as if you would type that in the terminal.\n",
    "\n",
    "So, this notebook will describe the assignment, give you the question that you need to complete and guide you through the assignment in steps. You should not use this notebook to actually program the code, other than for small things (like section 1 for today) or for calling other \"main\" files to get, print and plot the results. You should provide the textual as well as the numerical answers inline, after each question by running the right scripts that you should have implemented. Once you complete the assignment and answer the questions inline, you can download the report in pdf (File->Download as->PDF) and send it to us, together with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Implement your code and answer <b>all</b> the questions.\n",
    "Make your own bitbucket repository (bitbucket allows for private repositories).\n",
    "Commit your answers to the repository and invite us to access your solutions.\n",
    "<b>Please send your answers by February 10, at 23:59.</b>\n",
    "\n",
    "In the course there is a 7 late day policy.\n",
    "This means that you are allowed 7 days in total for delivering the assignments, you can use them as you please.\n",
    "Beyone that each extra late day will have a 10% penalty on your final score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "By the end of this practical you should:\n",
    "<ul>\n",
    "<li> be comfortable with Torch </li>\n",
    "<li> be able to produce visualizations of functions in Torch </li>\n",
    "<li> be able to use the optimization package in Torch to fit the parameters of a toy function to a given dataset </li>\n",
    "<li> Optionally, be able to implement your very own Perceptron. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1   Master Torch and Lua\n",
    "\n",
    "## Question 1.1 [+2 points]\n",
    "\n",
    "Define a 3x5 tensor containing row-wise the first 15 Fibbonaci numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2 [+3 points]\n",
    "\n",
    "Slice and print the tensor you defined to get different \"sub-tensors\" as in the the picture below\n",
    "\n",
    "<img src=\"images/matrix.png\">\n",
    "\n",
    "Please explain what is the difference between <tt>a[{{-1}, {}}]</tt> and <tt>a[{-1, {}}]</tt>.\n",
    "\n",
    "For your convenience we have added already a new code cell, where you can implement your answer. You can implement the code inline or write the implementation in a separate file in your folder and call it as we described above. If have not added a code cell, where you can provide your answer, insert one yourself below the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(a ....)\n",
    "print(a ....)\n",
    "print(a ....)\n",
    "print(a ....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3 [+2 points]\n",
    "\n",
    "In question 1.1 you defined a 2-d tensor. First, vectorize it so that it is still a 2-d tensor only containing 15 rows and 1 column. Then, vectorize it so that it is a 1-d tensor containing 15 elements. Last, create a new tensor that for copies of that column, so that in the end you have a 15x4 tensor.\n",
    "\n",
    "<i>Hint: For this question you can use the function <tt>torch.expand(...</tt>. Please explain what is the difference of this function from <tt>torch.repeatTensor(...)</tt>.</i>\n",
    "\n",
    "For your convenience we have added already a new code cell, where you can implement your answer. From now on if the question also requires some textual answer (like ere), please insert a new markdown cell, where you describe your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4 [+3 points]\n",
    "\n",
    "Fill in the third row and the second column with 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Section 2 Basic implementations, visualizations and optimizations\n",
    "\n",
    "Next, we will learn how to implement basic functions using Torch and Lua, find (local) minima using the optim package and visualizing the results.\n",
    "Let's assume we have the 1-d function\n",
    "\n",
    "$$f(x)=x^2+\\exp(|x|-x^2)$$\n",
    "\n",
    "whose plot should look like (rendered with Wolfram Alpha):\n",
    "\n",
    "<img src=\"images/function.gif\">\n",
    "\n",
    "$\\DeclareMathOperator*{\\argmin}{arg\\; min}$\n",
    "We want to find the location $x^*$, where $f(x)$ obtains its minimum value, i.e., $x^*=\\argmin_{x} f(x)$.\n",
    "To do this, we will be using the optimization package <i>optim</i> and more specifically going to optimize the function using the L-BFGS algorithm.\n",
    "To find the minimum of the function $f(x)$ L-BFGS requires the gradient $\\nabla_x f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 [+5 points]\n",
    "\n",
    "Implement and visualize function $f(x)$ in Torch, so that you obtain a similar plot. Either write the function inline, or write your code in a separate file and call it using the way we described in the beginning. The starter code for both this question and 2.2 is in the file \"implement_simple_function.lua\". Check for the TODO items and implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2  [+5 points]\n",
    "\n",
    "Solve for the gradient $\\nabla_x f(x)$.\n",
    "In your report write down the gradient $\\nabla_x f(x)$.\n",
    "The gradient plot should look like:\n",
    "\n",
    "<img src=\"images/gradient.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3  [+10 points]\n",
    "\n",
    "Use this gradient with the <tt>feval</tt> function of the <tt>optim</tt> package, using the L-BFGS optimization algorithm setting and the default parameters to compute the minimum.\n",
    "\n",
    "Note that since you want to find the minimum of the function, your optimization search will be for the point $x^*$ for which $f(x^*)\\neq(x), \\forall x$. Hence, your parameter <b>lies in</b> the input space <tt>x</tt>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 Fitting a function to data points\n",
    "\n",
    "In questions 2.1 you were asked to implement a function $f(x)$, its gradient $\\nabla_x f(x)$, and compute the minimum of $f(x)$.\n",
    "Now, let's assume that we are not given the function form, as in most cases in machine learning and applied statistics.\n",
    "Instead, we are given a bunch of points in space and we want to fit a parameteric model, which explains it pretty well.\n",
    "We are given the following point $(x, y)$ pairs.\n",
    "\n",
    "<img src=\"images/points.png\">\n",
    "\n",
    "We can see that the way the points are positioned on the plot, it looks a lot like our function $f(x)$ from question 2.1.\n",
    "However, it's only the shape that looks similar, the points are located somewhere else in space and they are even upside down.\n",
    "This means we need to fit our function $f(x)$ to our particular point set.\n",
    "To this end wee parameterize the components that control the shape and position of the function,\n",
    "\n",
    "$$\n",
    "f(x; \\theta)=\\theta_0 + \\theta_1 x^2+ \\theta_2 \\exp(\\theta_3 |x| - \\theta_4 x^2).\n",
    "$$\n",
    "\n",
    "Note that compared to the previous section, where the parameters where the inputs $x$.\n",
    "In this example, however, $x$ are the observed variables.\n",
    "Our parameters, instead, are the varables $\\theta$.\n",
    "Our goal now is to find the the optimal parameters $\\theta^*$ for which we could a render $\\hat{f}(x)$ function that would look plausible, given these points.\n",
    "\n",
    "You can use the starter function \"fit_simple_function.lua\". The points for this dataset are stored in the file \"points.dat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1  [+2 points]\n",
    "\n",
    "We first need to define a good loss function, which is going to inform us how bad our rendered $\\hat{f}(x)$ is from the actual values $y$. What could be a good cost function $\\mathcal{L}(x, y)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2  [+3 points]\n",
    "\n",
    "Solve for the gradient $\\nabla_\\theta f(x)$. Write down the gradient $\\nabla_\\theta f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3  [+5 points]\n",
    "\n",
    "Before starting working on the assignment, please make sure you have read the [introductory lecture](http://uvadlc.github.io/lecture_notes points]\n",
    "\n",
    "Implement the gradient function $\\nabla_\\theta f(x)$.\n",
    "Make sure your gradient outputs are correct.\n",
    "To do so you can implement some unit tests, although this is not required by the assignment.\n",
    "To implement a unit test, first define an input $x$.\n",
    "From question 3.2 you know what the gradient function should return in theory for that particular input.\n",
    "Compare what you should be getting in theory with what you get from your code.\n",
    "If you find this difficult, you can break the function in smaller functions, like $f_1(x)=\\theta_0+\\theta_1 x^2$, $f_2(x)=\\theta_2 \\exp(x)$ and $f_3(x)=\\theta_3 |x| - \\theta_4 x^2$ and implement the gradients for these functions individually.\n",
    "\n",
    "<i>Hint. For the implementations here check the math package in Torch. You probably gonna be needing functions like <tt>addcmul</tt>, <tt>mul</tt>, etc.</i>\n",
    "\n",
    "<i>Hint 2. It's good here if you define <b>by default</b> all your variables to be local. It's alright if you mess it up, you will get a runtime error and you will not have access to a variable. Then, you just drop the keyword local. It's much worse if you forget to add the keyword local and your variable changes values because of other, external functions. The problem in that case is that you will not get a runtime error, you will just get crazy numbers and you will not know where the problem is exactly.</i>\n",
    "\n",
    "<i>Hint 3. Make sure when you initialize your tensors, to set them to 0. Like in C/C++, Torch does not do that by default. If you don't do that, you might again get crazy numbers, especially if you use math functions like <tt>addcmul</tt>, that accumulate the output on an output variable that you must have defined earlier.</i>\n",
    "\n",
    "<i>Hint 2. It's good here if you define <b>by default</b> all your variables to be local. It's alright if you mess it up, you will get a runtime error and you don't have access to a variable. Then, you just drop the keyword local. It's much worse if you forget to add the keyword local and your variable changes values because of other, external functions. The problem in that case is that you will not get a runtime error, you will just get crazy numbers.</i>\n",
    "\n",
    "<i>Note. In Torch (unfortunately) you cannot simply multiply a tensor with a number using a \"*\" operator. You need to use a specialized function like <tt>torch.mul(...)</tt> that multiplies all tensor entries with a specific number.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.4  [+10 points]\n",
    "\n",
    "Now that you have implemented the gradients correctly, it's time to find the optimal parameters $\\theta^*$.\n",
    "Use the <i>conjucate gradient(CG)</i> algorithm from the optim package to find the parameters $\\theta$ that would fit $f(x; \\theta)$ to the point set optimally.\n",
    "\n",
    "Write down these parameters and plot the point set and the obtained function using the $\\theta$ parameters.\n",
    "Does the function make sense, namely does it fit well to the provided points?\n",
    "Change the optimization function from <i>conjugate gradient</i> to <i>stochastic gradient descent (SGD)</i>.\n",
    "Do you see any difference?\n",
    "If yes, please explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Section 4 Implement your own perceptron [optional, +20 points]\n",
    "\n",
    "Now that you have mastered the basics, you can implement your own simple perceptron from the 60's. You can use the algorithm as described in the lecture notes, or you can find much more material online, starting from [Wikipedia](https://en.wikipedia.org/wiki/Perceptron \"Perceptron\").\n",
    "\n",
    "Construct your own dataset sampled from two 2-d spherical gaussians, one with $(\\mu, \\sigma)=(-3, 1)$ and $(\\mu, \\sigma)=(3, 1)$. Build the perceptron algorithm and plot the solutions over time. Also plot the final solution.\n",
    "\n",
    "Repeat the experiment, now using samples from gaussians, one with $(\\mu, \\sigma)=(-0.5, 1)$ and $(\\mu, \\sigma)=(0.5, 1)$. What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
