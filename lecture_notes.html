<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Lecture Notes</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="../css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="../css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../css/creative.css" type="text/css">

    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="../index.html">Back to UvA Deep Learning Course</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="navbar-brand page-scroll" href="#page-top">Top</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#intro-to-torch">Intro to Torch</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#how-to-learn-with-neural-networks">How to learn with neural networks?</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#how-to-clasify-pixels">How to classify pixels?</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#how-to-synthesize-words">How to synthesize words?</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#unsupervised-bayesian-deep-learning">Unsupervised and Bayesian Deep Learning</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#the-bigger-picture">The bigger picture</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <h1>LECTURE NOTES</h1>
                <hr>
                <p>UvA Deep Learning Course</p>
                <a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>
            </div>
        </div>
    </header>

    <section class="bg-primary" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">About lecture notes</h2>
                    <hr class="light">
                    <p class="text-faded">Notes related to theory of Deep Learning, as discussed in the classroom. For convenience the lecture notes have been thematically organized, so that to give a more holistic understanding of the theory and the applications of Deep Learning.</p>
                    <a href="#" class="btn btn-default btn-xl">Get Started!</a>
                </div>
            </div>
        </div>
    </section>

    <section id="intro-to-torch">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">Intro to Torch</h2>
                    <hr class="primary">
                    
                    <p class="running-text" style="text-align:justify">

                    <b>Torch</b> is currently one of the most popular deep learning frameworks in top research labs around the world, such as Facebook and Google especially DeepMind.
                    Torch started from <a href="http://yann.lecun.com/">Y. LeCun's</a> lab, who is one of the leading experts in deep learning and <b>the</b> reference when working with convolutional neural networks.
                    In Torch there is a great array of existing codes, deep learning softwares and components that will make your life easy, especially once you successfully complete this course.

                    </p>

                    <p class="running-text" style="text-align:justify">
                    Torch sits on top of an existing programming language, <b>Lua</b>.
                    Lua is a lightweight, very fast multi-paradigm programming with a somewhat "Matlab"-like coding style.
                    Torch and Lua are rich in features and relatively easy to use and, therefore, are ideal for rapid prototyping.
                    However, they can be quite annoying in the beginning, because of some peculiarities.
                    </p>

                    <p class="running-text" style="text-align:justify">
                    Although Torch does not come with a graphical interface that would allow for easier programming, it does have a web interactive interface, namely <b>iTorch</b>.
                    For those of you familiar with <a href="http://jupyter.org/">Jupyter</a> notebooks for iPython, this should be quite easy.
                    Jupyter has implemented a Torch kernel, therefore, one can easily run torch software interactively on his/her web-browser as if he was running Matlab.
                    </p>

                    <p class="running-text" style="text-align:justify">
                    For those of you not familiar with Jupyter notebooks,
                    <blockquote cite="http://jupyter.org/">
                    <i>
                    The Jupyter Notebook is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more.
                    <footer>
                    <a href="http://jupyter.org/">The Jupyter Team</a>
                    </footer>
                    </blockquote>
                    </i>
                    </p>

                    <p class="running-text" style="text-align:justify">
                    The great thing about Jupyter notebooks is that you can start them as easily as just typing <tt>itorch notebook</tt> in your terminal (of course once you have iPython and iTorch installed).
                    </p>

                    <p class="running-text" style="text-align:justify">
                    Next, we will guide you through the installation process and provide you with some short tutorial in Lua, and a longer tutorial in Torch.
                    </p>

                    <h3 class="section-heading">Installing Lua and Torch</h3>

                    <p class="running-text" style="text-align:justify">
                    You do not need to explicitly install Lua, just install Torch and everything is going to work just fine.
                    To install Torch, <a href="http://torch.ch/docs/getting-started.html">please visit their website and follow the instructions.</a>
                    Although the basic installations are alright, you might experience some complications because of prior iPython installations.
                    In that you case you might need to rename some library files in the iPython installation (such libreadlince.* to something else -- do not delete them as you might need to bring them back in the future)
                    In any case, the installation should not take more than a few minutes if everything goes smoothly, or an hour if you have difficulties.
                    If you have difficulties that you cannot resolve, please <a href="http://lmgtfy.com/">lmgtfy</a> or ask a question in our virtual class in <a href="index.html#course-links">Piazza</a>.
                    </p>

                    <p class="running-text" style="text-align:justify">

                    At this point we have to note that Torch is mainly supported for X systems (Linux, OS X), but not Windows.
                    For those that cannot live without Windows for some reason, or that cannot have a separate partition where they install Ubuntu or Linux Mint, go to <a href="http://cilvr.nyu.edu/doku.php?id=software:torch:start#torch_tutorial_for_machine_learning">LeCun's NYU research group website</a>.
                    The simplest solution is to download this <a href="http://data.neuflow.org/share/Torch7.ova">Ubuntu virtual machine</a> they have prepared, which includes a pre-compiled, pre-installed version of Torch.
                    This virtual machine requires <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a>.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Once you have the basic Torch installation, you shoule install additional Torch packages that are very useful for this course and beyond.
                    To install new Torch packages one simply needs to type in his terminal <tt>luarocks install MyNewPackage</tt>.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    There are several useful or even necessary packages that you should now install: <tt>nn</tt>, <tt>gnuplot</tt>, <tt>optim</tt> and of course <tt>itorch</tt>.
                    For more packages you can visit the <a href="https://github.com/torch/torch7/wiki/Cheatsheet">Torch cheatsheet</a>.

                    </p>

                    <h4 class="section-heading">FAQ</h4>

                    <p class="running-text" style="text-align:justify">
                    To be filled in.
                    </p>                    

                    <h3 class="section-heading">Starting with Lua</h3>

                    <p class="running-text" style="text-align:justify">

                    There are dozens of tutorials for Lua out there.
                    Please, be patient enough to go through at least one, as there are certain Lua peculiarities that might make your life miserable, if you do not know them in advance.
                    Some tutorials that we found useful were the following:

                    </p>
                    
                    <p class="running-text">
                    <div align="left">

                    <ul class="running-text">
                    <li><a href="http://tylerneylon.com/a/learn-lua/" *-target="_blank">http://tylerneylon.com/a/learn-lua/</a></li>
                    <li><a href="http://luatut.com/crash_course.html" *-target="_blank">http://luatut.com/crash_course.html</a></li>
                    </ul>

                    </div>
                    </p>

                    <p class="running-text" style="text-align:justify">

                    Once you read these tutorials, you should be able to start some basic programming with Lua.
                    Before continuing, you should be confident in understanding the following concepts.<br><br>

                    <b>Defining new variables with <tt>=</tt> &nbsp; </b> The <tt>local</tt> works <u>like</u> in Python and <u>unlike</u> Matlab.
                    This means that once you declare a variable <tt>myvar = 10</tt> and then you define another variable <tt>myvar2 = myvar</tt>, the <tt>myvar2</tt> actually refers to the memory address of <tt>myvar</tt>.
                    Hence, if you change <tt>myvar2</tt>, also <tt>myvar</tt> will change.
                    If you want a clean fresh variable you should use <tt>copy()</tt>. <br><br>

                    <b>The keyword <tt>local</tt> &nbsp; </b> The <tt>local</tt> keyword is a very important concept to understand.
                    In Lua by default all variables are declard global, unless you add the keyword <tt>local</tt> in front, like <tt>local myvar = 10</tt>.
                    Although this might look like an innocent mistake, it can create complete chaos in combination with the <tt>=</tt>.
                    If you don't define you variable to be local inside your function <tt>fun1</tt> (e.g., you just type <tt>num_epochs=10</tt>), and accidentally (or not) have the same variable name in other functions <tt>funOthers</tt>, changing <tt>num_epochs</tt> in <tt>fun1</tt> will also affect the same variable in <tt>funOthers</tt>. 

                    Also, note that local variables only exist in standalone scripts that one runs from the terminal.
                    If you just start an interactive session with <tt>th</tt> or with iTorch, local variables do not make sense.
                    If you define one, you will simply not be able to access it. <br><br>

                    <b>Lua <tt>table</tt> &nbsp; </b> Lua does not have lists, arrays, dictionaries and all the exotic variations of "keeping things together in a single variable", like Python.
                    Instead, it has tables (and metatables), with which one can do pretty much the same things.
                    One can iterate of the table elements with <tt>ipairs</tt>.<br><br>

                    <b>The keyword <tt>require</tt> &nbsp; </b> The <tt>require</tt> keyword works like <tt>import</tt> in Python, namely to import packages to your script/function/file.
                    Beware that the same rules apply about the <tt>local</tt> keyword.
                    Unless you want the package to be accessible by all files, use the <tt>local</tt>.<br><br>

                    <!-- <b>Difference between <tt>a.f()</tt> and <tt>a:f()</tt> &nbsp; </b> <b>NOTE READY YET.</b>
                    With <tt>a.f()</tt> you need to explicitly add the function itself as first argument, with tt>a:f()</tt> this is implicitly added. -->

                    </p>

                    <h3 class="section-heading">Starting with Torch</h3>


                    <p class="running-text" style="text-align:justify">

                    Torch is a scientific computing framework with wide support for machine learning algorithms.
                    A basic component for machine learning and scientific programming are vectors, arrays, matrices, etc. 
                    Torch generalizes in an efficient manner vectors (1-d) and matrices (2-d) to tensors <tt>torch.Tensor()</tt> of n-dimensions.
                    By calling <tt>t = torch.Tensor(2, 3, 4, 5, 6)</tt> you get a new 5-d tensor <tt>t</tt>.

                    </p>

                    <p class="running-text" style="text-align:justify">
                    There are some nice tutorials out there about Torch. Consider some of the following:
                    </p>

                    <p class="running-text">
                    <div align="left">

                    <ul class="running-text">
                    <li><a href="http://code.madbits.com/wiki/doku.php?id=tutorial" *-target="_blank">http://code.madbits.com/wiki/doku.php?id=tutorial</a></li>
                    <li><a href="http://torch.ch/docs/tutorials-demos.html" *-target="_blank">http://torch.ch/docs/tutorials-demos.html</a></li>
                    <li><a href="http://atamahjoubfar.github.io/Torch_for_Matlab_users.pdf" *-target="_blank">http://atamahjoubfar.github.io/Torch_for_Matlab_users.pdf</a></li>
                    <li><a href="https://github.com/facebook/iTorch" *-target="_blank">https://github.com/facebook/iTorch</a></li>
                    </ul>

                    </div>
                    </p>

                    <p class="running-text" style="text-align:justify">
                    The two single most important classes of objects in Torch is the <a href="https://github.com/torch/torch7/blob/master/doc/tensor.md">tensor</a> and <a href="https://github.com/torch/torch7/blob/master/doc/maths.md">maths</a>.
                    The tensor class provides all sorts of functionalities for manipulating vectors, matrices and tensors.
                    The math class provides all sorts of mathematical functions necessary in every scientific programming framework.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    In large scale machine learning research memory and computational efficiency can be of paramount importance.
                    With Torch one can achieve high efficiency if one performs as many operations as possible in-place.
                    This means, you should try to avoid to define/call new variables, if you can reuse existing ones.
                    Through specialized functions Torch allows this to be done quite easily.
                    For example consider the following two cases.
                    </p>

<pre class="prettyprint"><code><div align="left">local t  = torch.Tensor(10, 10)
local t2 = torch.Tensor(10, 10)
t3       = t + t2</div></code></pre>

                    <p class="running-text" style="text-align:justify">

                    and

                    </p>

 <pre class="prettyprint"><div align="left">local t  = torch.Tensor(10, 10)
local t2 = torch.Tensor(10, 10)
t:add(t2)</div></pre>

                    <p class="running-text" style="text-align:justify">

                    In the first example a new variable, <tt>t3</tt>, is defined and new memory needs to be allocated.
                    If, however, <tt>t</tt>, is not needed anymore, we can just overwrite it to store the final summation.
                    As a result, we avoid allocating new resources.
                    Although this example is trivial, you might want to rethink it when you have matrices with millions of entries.
                    In general there are specialized functions for avoiding to performing specific tensor operations manually.
                    For example <tt>torch.expand([...])</tt> expands a tensor without allocating memory and <tt>torch.fill([...])</tt> fills in matrix entries without needing to run a for loop.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Although understanding things in theory are important, to become experts you need to start playing with code and programming.
                    We have prepared the <a href=practicals.html#practical-1>first practical</a> so that you familiarize yourself better with Lua and Torch, and more specifically with using tensors, writing functions, calling important packages like <tt>optim</tt> and <tt>itorch.Plot</tt>.

                    </p>

            </div>
        </div>
    </section>

    <aside class="bg-dark">
        <div class="container text-center">
            <div class="call-to-action">
                <h2>Suggested readings:</h2>

                <p class="text-faded">
                    <div align="left">

                    <ul class="text-faded">

                    <li> <a href="http://www.deeplearningbook.org/" target="_blank" style="color: white;">I. Goodfellow, Y. Bengio, A. Courville. <i>Deep Learning</i>, MIT Press (in preparation), 2016.</a> A book for everything related to Deep Learning. [All lectures]</li>

                    <li> <a href="http://arxiv.org/abs/1404.7828" target="_blank" style="color: white;">J. Schmidhuber. <i>Deep Learning in Neural Networks: An Overview</i>, arXiv, 2014.</a> A paper that summarizes the history of neural networks. [Lecture 1]</li>

                    <li> <a href="https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjn8O-CltnKAhVBjQ8KHfj4DD0QFggfMAA&url=http%3A%2F%2Fpsych.stanford.edu%2F~jlm%2Fpapers%2FPDP%2FVolume%25201%2FChap8_PDP86.pdf&usg=AFQjCNEyzSem3aZnXoNcuAXiOMEP5MwVtQ&sig2=EWxwboc4glWfSD6SzpQoQg" target="_blank" style="color: white;">D.E. Rumelhart, G.E. Hinton, R.J. Williams. <i>Learning representations by back-propagating errors.</i>, Nature, 1986.</a> A paper that summarizes the history of neural networks. [Lecture 1, 2]</li>

                    <li> <a href="http://www.cs.toronto.edu/~osindero/PUBLICATIONS/ncfast.pdf" target="_blank" style="color: white;">G.E. Hinton, S. Osindero, Y.W. Teh. <i>A Fast Learning Algorithm For Deep Belief Networks.</i>, Neural Computation, 2006.</a> A paper that marks the beginning of the Deep Learning era. [Lecture 1, 3]</li>

                    </ul>

                    </div>
                    </p>  
                
            </div>
        </div>
    </aside>

    <section id="how-to-learn-with-neural-networks">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">How to learn with neural networks [UNDER CONSTRUCTION]</h2>
                    <hr class="primary">

                    <p class="running-text" style="text-align:justify">

                    <h3 class="section-heading">What is a neural network?</h3>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    A neural network is a family of parametric, non-linear and hierarchical representation learning functions, which are massively optimized with stochastic gradient descent to encode domain knowledge, i.e. domain invariances, stationarity.
                    Mathematically, this verbal definition is described as

                    $$a_L(x; \theta_{1, ..., L})=h_L(h_{L-1}(...h_1(x, \theta_1)..., \theta_{L-1}), \theta_L).$$

                    In this definition the output of a module becomes (part of) the input in a subsequent module, which is higher in the hierarchy of the functions that constitute the neural network.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>A neural network is a parametric</b> class of models, because the parameters $\theta_{1, ..., L}$ need to be trained to minimize the empirical risk on a training set.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>A neural network is in its general form non-linear</b>, as some of the functions $h_1, ..., h_L$ are non-linear.
                    Although one could also a design a neural network with only linear layers, that would be in vain, as it would practically amount to a series of matrix multiplications.
                    As such, it could be replaced by a single matrix multiplication, that is by a single layer neural network.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>A neural network is hierarchical</b>, because the non-linear functions $h_1, ..., h_L$ are nested one inside the other.
                    The order with which they are placed defines the hierarchy.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>A neural networks learns representations</b> through the non-linear functions $h_1, ..., h_L$.
                    More specifically, a neural network should receive inputs that are raw as possible (although the right data preprocessing and normalization is important).
                    Starting from this raw input, the non-linear functions learn co-hierarchical co-dependencies, or features.
                    For new test samples, which resemble the training samples the features were learnt upon, these features should become stronger.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>A neural networks is massively optimized</b> because it contains a great deal of parameters.
                    As such, without the right amount of data our neural network will overfit tremendously, leading to unusable models.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    <b>Last, a neural networks learns domain knowledge</b>, as the hypothesis is by encoding this domain knowledge in its features, the neural network can fit better the underlying data distributions, while being more (controllably) invariant to the unespabable dataset noise.

                    </p>

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    $\DeclareMathOperator*{\argmin}{arg\; min}$
                    During training the goal is to find the optimal parameters $\theta^*$ which minimize the empirical risk both on the training and a separate validation set.
                    Mathematically, we write this as
                    
                    $$\theta^* \leftarrow \argmin_{\theta} \frac{1}{n} \sum_{i=1}^n \mathcal{L}(\theta; x_i, y_i) \;\; (1)$$
 
                    To find the optimal parameters of a neural netowrk, we almost always use some variant of Gradient Descend

                    $$
                    \theta^{(t+1)}=\theta^{(t)}-\frac{\eta_t}{n} \sum_i \nabla_{\theta} \mathcal{L}(\theta^{(t)}; x_i, y_i) \;\; (2)
                    $$

                    All there is to a neural network, be it model details, architecture and learning are summarized by eq. (1) and (2).

                    </p>

                    <h3 class="section-heading">Everything is a module</h3>
                    <!-- Architectural details -->

                    <p class="running-t$x^*=\argmin_{x} f(x)$ext" style="text-align:justify">

                    From a system engineering point of view, a neural network is as a pipeline of connected modules.
                    The way the modules are connected define the network architecture.
                    Each of these modules implement a particular function.
                    The input of a module is the output of one or more modules from below, while in turn the output of that module becomes the input for another module.
                    The only exception is the data layer module.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Two main operations define the training of a neural network, namely the forward and the backward propagation of flows, better known as the forward propagation and backpropagation.
                    During the forward propagation the network gets activated based on a particular input, e.g. based on an image that the network received.
                    During the backpropagation the gradients of the neural network loss function with respect to the network parameters are computed.
                    These gradients are then used to update the parameters with Gradient Descend.

                    </p>                    

                    <p class="running-text" style="text-align:justify">

                    Every module is independent from almost all other modules.
                    The only things any module needs to know are <i>(a)</i> to what modules is the input directly connected to and, <i>(b)</i> what are its parameters.
                    The architect can thereafter increase the neural network complexity by combining different modules of various purposes and sophistications into all sorts of crazy architectures.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    This design philosophy has three strong advantages.
                    First, as long as the modules meet certain requirements, which we are going to revisit later, one can build as complex modules as one desires.
                    Whether one module is complex or not, it will not affect the operationality of the overall network.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Second, as long as one can define a meaningful forward and backward propagation of flows, one is free to design a wide variety of different neural network architectures and connectivities, ranging from feedforward networks to loopy networks.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Third, given good modularity it is much easier to "debug" a complicated architecture with "unit tests".
                    A unit test is a test where one checks whether a module produces the output, which the theory predicts, given a standard predefined input.
                    For example, if our module is designed to compute the square root of any number, when we define it's input to be "9", "16", "25", it should return "3", "4", "5".
                    Since we can now verify the correctedness of each module independently, we can build very complicated networks and still be sure to backtrace future problems relatively easily.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Architectures that have only forward connections are called feedforward neural networks and are straightforward to implement.
                    Architectures that have forward connections between layers, which, however, are not adjacent to each other, form directed acyclic graphs (DAG) networks or DAGNN.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    A frequently used term in DAGNNs is <b>skip layers</b>.
                    A layer that has forward connections not only to its immediate adjacent layers is a skip layer.
                    DAG networks are also quite easy to implement as again, a given module is agnostic to the incoming inputs.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Architectures that have layers connected in cycles form loopy networks.
                    These are recurrent neural networks.
                    Loopy networks are more complicated, since training and inference cannot be performed in a straightforward manner.
                    Instead, they have to be unrolled in time.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    An important note here is that although one can design crazy neural network architectures, this does not mean one should.
                    Less complicated modules, e.g. <i>ReLUs</i> instead of <i>tanh</i>, are usually better theoretically as well as experimentally, while they are easier to train and generalize better.
                    
                    </p>

                    <h3 class="section-heading">Computing the gradients with Backpropagation</h3>

                    <p class="running-text" style="text-align:justify">

                    Backpropagation is the single most popular algorithm for training neural networks.
                    Let's assume we have the network below, composed of $L$ layers.
                    The per layer activations based on the module functions per layer are:

                    $$\begin{eqnarray}
                    a_1 = h_1(x_1, \theta_1), \\
                    a_2 = h_2(x_2, \theta_2), \\
                    a_3 = h_3(x_3, \theta_3), \\
                    \dots, \\
                    a_L = h_L(x_L, y), \\
                    \end{eqnarray}$$

                    where $x_l=a_{l-1}$.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    where the last layer module equals to the loss function for our network.
                    To make the explanations more hands-on, let us accompany the formal definitions with the specific neural network from the figure above.
                    The first module (layer) is linear, receives the 256-d data from the data input module and projects them via a matrix-matrix multiplication onto a 128 space,
                    
                    $$a_1 = \theta_1 x_1.$$
                    
                    Hence, $dim(x_1)=[256\times 1]$, $dim(a_1)=[128\times 1]$ and $dim(\theta_1)=[128\times 256]$
                    The second module receives the input from module 1, so $x_2=a_1$ and applies a non-linear sigmoid transformation, namely
                    
                    $$a_2 = \sigma(x_2).$$

                    The second module does not contain any trainable parameters and only applies the sigmoid non-linearity to the data.
                    Hence, $\theta_2=\emptyset$.
                    Similarly, we consider for the next to layers to be implemented by a linear module projecting the input to a 64 dimensional space,

                    $$a_3 = \theta_3 x_3$$

                    and a ReLU module with no trainable parameters,

                    $$a_4 = ReLU(x_4).$$

                    The last layer is impemented by a cross entropy (negative log-likelihood) module, namely

                    $$a_5 = \mathcal{L}(x_5, y)=0.5\|y-x_5\|^2.$$

                    Remember that in all cases $$x_l=a_{l-1}$$.
                    

                    </p>

                    <p class="running-text" style="text-align:justify">

                    To optimize the network, namely to find the optimal weights $\theta_l, l=1, \dots, L-1$, we se (stochastic) gradient descent.
                    Hence, we need to compute all the gradients of the network with respect to the weights, namely $\dfrac{\partial{\mathcal{L}}}{\partial \theta_l}, l=1, \dots, L-1$
                    The module of layer $L$ implements the loss function, therefore does not contain any parameters.
                    For layer $L-1$ we have parameters $\theta_{L-1}$, hence no gradient need to be computed.
                    For all other layers, however, we can have potentially gradients.
                    For the module of layer $L-1$, given the good old \emph{chain rule} for computing the derivatives adn the loss function $\mathcal{L}$ (normally we should write it as $\mathcal{L}(x_L, y_L)$, but we opt for $\mathcal{L}$ for consiceness), we have for

                    $$\begin{eqnarray}
                    \dfrac{\partial \mathcal{L}}{\partial \theta_{L-1}} & = & \dfrac{\partial \mathcal{L}(a_{L-1}, y_L)}{\partial \theta_{L-1}} 
                    & = &
                    \dfrac{\partial \mathcal{L}}{\partial{a_{L-1}}} \dfrac{\partial a_{L-1}}{\partial{\theta_{L-1}}}
                    \end{eqnarray}$$

                    </p>

                    <!-- <footer>
                    <a href="http://jupyter.org/">The Jupyter Team</a>
                    </footer>
                    </blockquote>
                    </i>
                    </p>
 -->
                    <p class="running-text" style="text-align:justify">

                    Generally, for the module of layer $l$ we would have that

                    </p>

                    <p class="running-text" style="text-align:justify">

                    $$\begin{eqnarray}
                    \dfrac{\partial \mathcal{L}}{\partial \theta_l} = \dfrac{\partial \mathcal{L}}{\partial{a_l}} \dfrac{\partial a_l}{\partial{\theta_l}}
                    \label{eq:grad-layer}
                    \end{eqnarray}$$

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Eq.~\eqref{eq:grad-layer} provides us with a pretty straightforward way of computing the gradients for layer $l$.
                    We first need the gradient of the module w.r.t. each parameters $\dfrac{\partial a_l}{\partial{\theta_l}}$, which is easy to compute provided the module activation function is a (almost everywhere) differentiable function.
                    For example, if our module $l$ had the activation function $a_l=h_l(x_l, \theta_l)=\sqrt{\theta_l \cdot x_l}$, we would simply have $\dfrac{\partial a_l}{\partial{\theta_l}}=\dfrac{-0.5 x_l}{\sqrt{\theta_l \cdot x_l}}$.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Second, we need the gradient of the loss function with respect to the output of layer $\dfrac{\partial \mathcal{L}}{\partial{a_l}}$.
                    Given that between the loss function $\mathcal{L}$ and the module of layer $l$ there might be several other layers, if we would explicitly write down the full equation would yield a very complicated function.
                    However, we notice that we could decompose $\dfrac{\partial \mathcal{L}}{\partial{a_l}}$ as

                    $$
                    \dfrac{\partial \mathcal{L}}{\partial{a_l}} = \dfrac{\partial \mathcal{L}}{\partial{a_{l+1}}} \dfrac{\partial a_{l+1}}{\partial{a_l}}
                    $$

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Hence, we rewrite the gradient w.r.t. the output of layer $l$ as the gradient w.r.t. the output of layer $l+1$, times the gradient of output of layer $l+1$ w.r.t. to the output of layer $l$, $\partial a_{l+1} / \partial{a_l}=\partial a_{l+1} / \partial{x_{l+1}}$.

                    </p>

                    <p class="running-text" style="text-align:justify">
                    
                    As such, we can simply compute the gradients $\dfrac{\partial \mathcal{L}}{\partial{a_l}}, l=1, ..., L$ recursively: compute first the gradient $\partial \mathcal{L}/\partial{a_{L-1}}$ for layer $L-1$, then use $\partial \mathcal{L}/\partial{a_{L-1}}$ to compute the gradient $\partial \mathcal{L}/\partial{a_{L-2}}$ for layer $L-2$ and so on.

                    </p>


                    <p class="running-text" style="text-align:justify">

                    It is important here to draw the attention to $\partial a_l/\partial{x_l}$.
                    On a first sight this a simple derivation.
                    This is indeed the case, when a specific output dimension $a_l^j$ relates only to the respective input dimension $x_l^j$.
                    Such a case is for \emph{elementwise} functions, like $a_j=h(x_j)=\tanh(x_j), \forall j$, or $a_j=h(x_j=\text{ReLU}(x_j), \forall j$, where the nonlinearities are applied on each dimension independently.
                    However, there are functions and modules, where an output dimension relates to multiple input dimensions, $a_j=h(x_1, \dots, x_j, x_{j+1}, \dots)$.
                    Such a a function is the softmax 

                    $$
                    a_j = \dfrac{\exp{x_j}}{\sum_i{\exp{x_i}}}
                    $$

                    or the $\ell_2$ normalization function

                    $$
                    a_j = \dfrac{x_j}{\sqrt{\sum_i{x_i^2}}}
                    $$

                    </p>

                    <p class="running-text" style="text-align:justify">

                    As for these functions each output dimension relates to multiple input dimension, to compute $\partial a_l/\partial{x_l}$ actually means that one needs to compute the Jacobian matrix

                    $$
                    \dfrac{\partial a_l}{\partial{x_l}}=
                    \begin{bmatrix}
                    \dfrac{\partial a_l^1}{\partial{x_l^1}} & \dfrac{\partial a_l^1}{\partial{x_l^2}} & \dots & \dfrac{\partial a_l^1}{\partial{x_l^n}} \\ 
                    \dfrac{\partial a_l^2}{\partial{x_l^1}} & \dfrac{\partial a_l^2}{\partial{x_l^2}} & \dots & \dfrac{\partial a_l^2}{\partial{x_l^n}} \\ 
                    \dots                          & \dots & \dots & \dots \\ 
                    \dfrac{\partial a_l^m}{\partial{x_l^1}} & \dfrac{\partial a_l^2}{\partial{x_l^2}} & \dots & \dfrac{\partial a_l^m}{\partial{x_l^n}}
                    \end{bmatrix}
                    $$

                    In that case to compute $\dfrac{\partial \mathcal{L}}{\partial{a_l}}$ we have to perform a matrix multiplication of the gradient vector $\dfrac{\partial \mathcal{L}}{\partial{a_{l+1}}}$ and the Jacobian $\dfrac{\partial a_{l+1}}{\partial{x_{l+1}}}$.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Although keeping up with all these operations can be confusing, a good way to make sure that all operations are done flawlessly is to resort to dimension analysis.
                    More specifically, if the parameter matrix for layer $l$ have dimensions $d_{l-1} \times d_l$, then the gradient w.r.t. to the parameter matrix must also have the same dimensions.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Now that we have an easy way to compute $\dfrac{\partial \mathcal{L}}{\partial{a_l}}, l=1, ..., L$, and given that we can easily compute $\dfrac{\partial a_l}{\partial{\theta_l}}$ and $\partial a_{l+1}/\partial{x_{l+1}}$, we can summarize the backpropagation algorithm for computing the network gradients.

                    </p>

                    <p class="running-text" style="text-align:justify">

<div style="border:1px solid black;" align="left">
<p><b>Step 1.</b> Set $l=L$</p>
<p><b>Step 2.</b> Set $\delta_L=\dfrac{\partial \mathcal{L}}{\partial{a_{L}}}=I$, since this operation practically stands for the derivative of a function with respect to its output.</p>
<p><b>Step 3.</b> $l\leftarrow l-1$</p>
<p><b>Step 4.</b> If convergence, exit.</p>
<p><b>Step 5.</b> Compute $\dfrac{\partial \mathcal{L}}{\partial{a_l}}=(\dfrac{\partial a_{l+1}}{\partial{x_{l+1}}})^T \dfrac{\partial \mathcal{L}}{\partial a_{l+1}}$</p>
<p><b>Step 6.</b> Set $\delta_l \leftarrow \dfrac{\partial \mathcal{L}}{\partial{a_{L}}}$</p>
<p><b>Step 7.</b> Compute $\dfrac{\partial \mathcal{L}}{\partial{\theta_l}}=\dfrac{\partial \mathcal{L}}{\partial{a_l}} \dfrac{\partial a_l}{\partial{\theta_l}}$</p>
<p><b>Step 8.</b> GOTO Step 3.</p>
</div>

                    </p>

                    <h4 class="section-heading">Implementing your own module</h4>

                    <p class="running-text" style="text-align:justify">

                    To implement a new module, you must first define the forward pass of the module, $a=h(x;\theta)$, where $a$ are the activations and $h(\cdot)$ the module function.
                    Implementing the forward pass is relatively straightforward.
                    Then, you must define the backward pass used by backpropagation to compute the gradients of the module with respect to the input $x$ and the module parameters $\theta$, if the module has trainable parameters.
                    Implementing the backward pass is slighlty more complicated, as you need to calculate the module gradient first.

                    </p>

                    <p class="running-text" style="text-align:justify">

                    Hence, to implement our <i>isolated</i> module to backpropagate its gradients, what we really care about are:
                    <ul>
                    <div align="left">
                    <li> the input $x$ to the module </li>
                    <li> the error gradients from the module above </li>
                    <li> and of course the gradient equation of the module with respect to the input and the gradient parameters.</li>
                    </div>
                    </ul>

                    </p>

                    <h4 class="section-heading">Gradient checks and Jacobians</h4>



                    </p>

                    <h3 class="section-heading">Types of modules</h3>

                    <h3 class="section-heading">Data preprocessing and normalization</h3>

                    <h3 class="section-heading">Optimization methods</h3>

                    <h3 class="section-heading">Regularization</h3>

                    <h3 class="section-heading">Learning rate</h3>

                    <h3 class="section-heading">Weight initialization</h3>

                    <h3 class="section-heading">Loss functions</h3>

                    <h3 class="section-heading">Babysitting a neural network</h3>

                    <h3 class="section-heading">What is a module</h3>


                    <h3 class="section-heading">Backpropagation</h3>

                    

                    <!-- As mentioned above, backpropagation is composed of two half-steps, forward and backward propagation.
                    During the forward propagation the module generates an output given an input.
                    If we would have a module for computing the input to the power of two, $f(x)=x^2$, during forward propagation we simply do that, namely compute the $x^2$.
                    This step is essentially the same as when we use the network at test time and use it to generate an output given an input.
                    The backward propagation is essentially very similar to the forward propagation, instead now we use the gradient of the module function to compute the output, namely $\nabla_x f(x)=2x$. -->


                    
<!--                     A feedforward, multi-layer neural network, like in the figure below, is often called also multi-layer perceptron <b>(MLP)</b>.
                    Each layers hosts a module like the ones we discussed earlier.

                    Each module receives an input and performs an operation on it, be it a linear transformation of the form $y=Wx+b$ or a non-linear one like $y=tanh(x)$ or pooling.
                    Also, typically there are connections only from layer $l$ to the subsequent one $l+1$, as in the figure to the right.
                    Hence, when we design our multilinear perceptron, the possible design choices we have, outside the learning hyperparameters, are the following: -->
<!--                     %
                    \begin{itemize}
                    \item number of modules
                    \item number of units in each module
                    \item type of operation applied inside each module
                    \item type of loss function
                    \end{itemize} -->


                </div>
            </div>
        </div>
    </section>

    <aside class="bg-dark">
        <div class="container text-center">
            <div class="call-to-action">
                <h2>Suggested readings:</h2>

                <p class="text-faded">
                    <div align="left">

                    <ul class="text-faded">

                    <li> <a href="https://www.google.nl/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjn8O-CltnKAhVBjQ8KHfj4DD0QFggfMAA&url=http%3A%2F%2Fpsych.stanford.edu%2F~jlm%2Fpapers%2FPDP%2FVolume%25201%2FChap8_PDP86.pdf&usg=AFQjCNEyzSem3aZnXoNcuAXiOMEP5MwVtQ&sig2=EWxwboc4glWfSD6SzpQoQg" target="_blank" style="color: white;">D.E. Rumelhart, G.E. Hinton, R.J. Williams. <i>Learning representations by back-propagating errors.</i>, Nature, 1986.</a> A paper that summarizes the history of neural networks. [Lecture 1, 2]</li>

                    <li> <a href="http://www.cs.toronto.edu/~osindero/PUBLICATIONS/ncfast.pdf"  target="_blank" style="color: white;">G.E. Hinton, S. Osindero, Y.W. Teh. <i>A Fast Learning Algorithm For Deep Belief Networks.</i>, Neural Computation, 2006.</a> A paper that marks the beginning of the Deep Learning era. [Lecture 1, 3]</li>

                    <li> <a href="http://www.cs.toronto.edu/~osindero/PUBLICATIONS/ncfast.pdf" target="_blank" style="color: white;">Y. LeCun, L. Bottou, G. B.Orr, K.R. Muller <i>Efficient Backprop.</i>, Lecture Notes in Computer Science, 2002.</a> A paper that describes very well how to train Neural Networks in practice. The writing is very clear and most of the tips are still useful for modern Deep Learning architectures. Highly Recommended! [Lecture 2, 3]</li>

                    <li> <a href="http://research.google.com/archive/large_deep_networks_nips2012.html" target="_blank" style="color: white;">J. Dean, G.S. Corrado, R. Monga, K. Chen, M. Devin, Q.V. Le, M.Z. Mao, M.A. Ranzato, A. Senior, P. Tucker, K. Yang, and A.Y. Ng <i>Large Scale Distributed Deep Networks.</i>, NIPS, 2012.</a> A paper that compares L-BFGS with SGD. [Lecture 3]</li>

                    <li> <a href="http://cs231n.github.io/neural-networks-1/" target="_blank" style="color: white;">http://cs231n.github.io/neural-networks-1/</a>, <a href="http://cs231n.github.io/neural-networks-2/" target="_blank" style="color: white;">http://cs231n.github.io/neural-networks-2/</a>, <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" style="color: white;">http://cs231n.github.io/neural-networks-3/</a> A. Karpathy <i>CS231n Convolutional Neural Networks for Visual Recognition.</i> The course website for A. Karpathy's and Fei-Fei L.'s class on Convolutional Neural Networks. A very nice and clean website, with very clear explanations on neural networks. Highly Recommended! [Lecture 2-4]</li>

                    <li> <a href="http://arxiv.org/abs/1206.5533" target="_blank" style="color: white;">Y. Bengio <i>Practical recommendations for gradient-based training of deep architectures.</i>, arXiv, 2012.</a> [Lecture 2, 3]</li>

                    <li> <a href="http://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf" target="_blank" style="color: white;">L. Bottou <i>Stochastic Gradient Descent Tricks.</i>, Lecture Notes in Computer Science, 2012.</a> [Lecture 2, 3]</li>

                    <li> <a href="http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf" target="_blank" style="color: white;">J. Martens <i>Deep learning via Hessian-free optimization.</i>, Lecture Notes in Computer Science, 2012.</a> [Lecture 3]</li>

                    </ul>

                    </div>
                    </p>  
                
            </div>
        </div>
    </aside>


    <section id="how-to-clasify-pixels">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">How to classify pixels?</h2>
                    <hr class="primary">

                    <p class="running-text">Not ready yet.</p>
                </div>
            </div>
        </div>
    </section>
    <section id="how-to-synthesize-words">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">How to synthesize words?</h2>
                    <hr class="primary">

                    <p class="running-text">Not ready yet.</p>
                </div>
            </div>
        </div>
    </section>
    <section id="all-things-unsupervised">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Unsupervised and Bayesian Deep Learning</h2>
                    <hr class="primary">

                    <p class="running-text">Not ready yet.</p>
                </div>
            </div>
        </div>
    </section>
    <section id="The bigger picture">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">The bigger picture</h2>
                    <hr class="primary">

                    <p class="running-text">Not ready yet.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/jquery.fittext.js"></script>
    <script src="js/wow.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/creative.js"></script>

</body>

</html>
